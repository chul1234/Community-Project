분류모델
학습시킬때 

회귀
예측값 데이터의y 값 비교 오차를 최소로 하는 것을 찾는다
오차를 정의하는것 오차 함수
회귀모델에서는 mse를 사용(mse:예측값 데이터의y 값 비교 오차의 제곱)

분류
예측값 데이터의y 값 비교 오차를 최소로 하는 것을 찾는다
오차함수는 NLL를 사용 (NLL최대값을 가지거나 최소값을 가지는 모델)

모델 훈련 -> 비용함수
최적화를 위한 미분가능
규제를 포함
mse,log-likelihood,gini-impurity 등

테스트 -> 예측성능지표
미분 가능 필요X 최종 목표와 가능한 가까워야 함
규제 관계 X
rmse,정밀도, 재현율(이거 사용 안하고 다른거 사용)

페이지4
비용함수 
rse= (데이터y값 - 예측y값)^2
단위 : 출력변수의 단위제곱
회귀모델의 예측 성능을 직관적으로 파악이 어려움

예측 성능지표
rmse = mse의 루트 씌운것
단위: 출력변수 단위와 동일
회귀모델의 예측 성능을 직관적으로 파악이 쉬움

페이지5
로지스틱의 경우 
log-likelihood = ln Π𝑖 𝜋 (𝑿𝑖)^𝑦𝑖(1 − 𝜋 𝑿𝑖 )^1−𝑦

예측 성능지표
사람이 보기 편해야 한다. 비용함수로는 이해하기가 어렵다

페이지 6
혼동행렬(2진분류)
데이터 실제 클래스(Y) , 예측클래스(^Y)를 비교하는 행렬
2진이라 1,0으로 나눔 
예측이 기준이다.
실제,예측이 다 positive일때 TP
실제 positive, 예측 negative FN
실제 negative, 예측 positive FP
실제 negative, 예측 negative TN
이거 전부 더하면 전체 데이터 포인트가 된다.
클래스 별로 잘 분류한 포인터와 잘못 분류한 포인트 수 행렬을 나타냄

페이지 8
평가지표(외워)를 만든다
1. sensitivity(recall,true positive rate)= TP%TP+FN(민감도)
2. specificity(True Negative rate)=TN%FP+TN (특이도)
3. False positive Rate = FP%FP+TN=1-TNR(특이도와 분모가 같다. 특이도와 더하면 1 )
4.False Negative rate = FN%TP+FN=1-TPR(민감도와 분모가 같다. 민감도와 더하면 1)
5.precision=TP%TP+FP(정밀도)
6.Accuracy = TP+TN%TP+FN+FP+TN(정확도)
7.F1 score 2*recall*precision % recall+prcision

페이지 10
페이지 11
test dataset 샘플갯수 10
input(토익시험의 영향을 끼치는 값)값 해외연수 기간, 영어공부시간
하면 logistic은 y값을 가질 확률을 준다(예측 확률)
일반적인 문턱값 : 0.5 (정해진값X)

문턱값성능지표의 값변화
cut-off value(threshold) 가 커질수록 tpr,fpr은 감소, tnr,fnr은 증가

최적의 문턱값(treshold) 결정은 단순한 문제가 아니다.
treshold 0으로 하면 전부다 positive로 한다. -> fn,tn은 0이다. 
threshold 1로 하면 전두다 negative로 한다. -> tp,fp는 0이다.

reciver oerating charcateristics(ROC) curve
x축  false positive rate
y축 true positverate rate
- (0, 0): 임계값이 높아 모두 negative로 예측하는 경우

- (1, 1): 임계값이 낮아 모두 positive로 예측하는 경우

- (0, 1): FP = 0, TP = 1인 완벽한 분류기
 
- ROC 곡선이 좌상향일수록 모델 성능이 우수하다고 할 수 있음


ROC 곡선 하부의 면적 (AUC)
좌상향 할수록 (AUC) 값이 클수록 좋은 모델이다.
0.5~0.6 안좋다
0.6~0.7 여전히 안좋다
0.7~0.8 중간이다.
0.8~0.9 훌륭하다
0.9~1.0 완벽하다
슬라이드 15는 나중에 한다(제목은 알아두어라)

trade-off(하나가 올라가면 하나는 낮아진다)
FNR과 FPR trade-off관계다.
recall(재현율) 과 precision은 trade-off 관계다.(분모는 TPR)
문제에 따라 recall과precision중 뭐가 중요한지 생각해야한다

페이지 20
클래스가 비율이 맞지 않는 데이터셋

페이지 21
const : 지불해야하는 값
actual positive class인 샘플을 잘못 분류 했을때의 const가 큼
profits: 
일반적으로 actual positive class인 샘플을 잘 분류했을때의 이득이 더큼
s
페이지 22
option2 는 38명한테 광고 책자를 주었다. 






